\documentclass{acm_proc_article-sp}

\begin{document}

\title{Monte Carlo Tree Search Tree Policies}
\subtitle{Randomized Algorithms}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Vincent Hellendoorn \\
       \affaddr{Msc Computer Science, TU Delft}\\
       \email{v.j.hellendoorn@student.tudelft.nl}
% 2nd. author
\alignauthor
Kaj Oudshoorn \\
       \affaddr{Msc Computer Science, TU Delft}\\
       \email{k.oudshoorn-2@student.tudelft.nl}
}

\maketitle
\begin{abstract}
Abstractive stuff
\end{abstract}

\section{Introduction}

\section{Monte Carlo Tree Search}

Monte Carlo Tree Search is a heuristic algorithm that is used for online planning. It is easiest explained in relation to games. Take for example a game of chess. The goal is to capture the opponents king while keeping your own king safe. However, in order to obtain that goal a number of moves have to be made by you and your opponent alternatively. Deciding which move to make, given the state of the game is key to winning the game. Moves can have direct rewards (like the capture of an opponents piece), but in general the effect of a move is only noticed a few turns after it has been made. For this reason it is hard to estimate how good a move is, without thinking a few steps ahead. Thinking ahead is, however, considerably hard, given the number of options a player has each turn. At the start of the game, a player can make 20 different moves (sixteen with pawns, four with knights), likewise his opponent also has 20 different moves, resulting in 400 possibilities in the first two moves alone. %TODO

Instead of looking through all the combinations of actions and observations, MCTS iteratively samples a selected number of actions and evaluates them through simulation. The resulting value is propagated back through the tree and updates the expected value of each action. After a number of these iterations (called simulations), the action with the highest expected reward is performed (followed by an observation) and the algorithm continues with the obtained state in order to decide the next action. Selecting the to-be-simulated action path is performed by the Tree Policy. The goal of the policy is to find a balance between exploration and exploitation. Exploration is choosing those actions that have not been sampled much so far. Exploitation is about more extensively searching in the direction of actions you already have high expectations from. 

\section{Tree Policies} 

\subsection{UCB1}
UCB stands for Upper Confidence Bounds. It is one of the most standard and well known method in MCTS. The method involves taking a decision based on exploration (finding new, possible optimal, paths) and exploitation (traversing already well performing paths). With this in mind, possible actions are evaluated with the following formula:
\begin{equation}
UCT = \bar{X}_j + 2 C_p\sqrt{\frac{2 \ln n}{n_j}}
\end{equation}
Where $j$ is a child node, $\bar{X}_j$ is the estimated value of $j$, $C_p > 0$ a constant, $n$ the amount of visits of the current node and $n_j$ the amount of visits of $j$.

When each value is obtained for all the child nodes, child with the maximum value will be traversed. It can be seen that $C_p$ can be adjusted to lower or increase the amount of exploration used in contrast to the exploitation of the estimated value $\bar{X}_j$.

\subsection{$\epsilon$-Greedy}

Another well known method is the $\epsilon$-Greedy method. Here, the best estimated child is usually visited, but with a probability $\epsilon$ a child is selected at random, uniformly, independent of the $\bar{X}_j$.

\subsection{SoftMax}
A different approach of the $\epsilon$-Greedy method is SoftMax. Instead of constantly using the same strategy, it uses a variable temperature $\tau$ such that at the start of the algorithm, exploration is preferred and towards the end, exploitation is preferred. 

As such, a child $j$ is visited with probability:
\begin{equation}
P(j) = \frac{e^\frac{\bar{X}_j}{\tau}}{\sum_{b=1}^{n} e^\frac{\bar{X}_j}{\tau}}
\end{equation}
When $\tau$ is large, $P(j)$ approaches a uniform distribution that is independent on $\bar{X}_j$. When $\tau$ approaches zero, SoftMax becomes more greedy. In this sense, SoftMax is quite similar to the local searcher Simulated Annealing.


\end{document}