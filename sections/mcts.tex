\section{Monte Carlo Tree Search}

Monte Carlo Tree Search is a heuristic algorithm that is used for online planning. It is easiest explained in relation to games. Take for example a game of chess. The goal is to capture the opponents king while keeping your own king safe. However, in order to obtain that goal a number of moves have to be made by you and your opponent alternatively. Deciding which move to make, given the state of the game is key to winning the game. Moves can have direct rewards (like the capture of an opponents piece), but in general the effect of a move is only noticed a few turns after it has been made. For this reason it is hard to estimate how good a move is, without thinking a few steps ahead. Thinking ahead is, however, considerably hard, given the number of options a player has each turn. At the start of the game, a player can make 20 different moves (sixteen with pawns, four with knights), likewise his opponent also has 20 different moves, resulting in 400 possibilities in the first two moves alone. %TODO

Instead of looking through all the combinations of actions and observations, MCTS iteratively samples a selected number of actions and evaluates them through simulation. The resulting value is propagated back through the tree and updates the expected value of each action. After a number of these iterations (called simulations), the action with the highest expected reward is performed (followed by an observation) and the algorithm continues with the obtained state in order to decide the next action. Selecting the to-be-simulated action path is performed by the Tree Policy. The goal of the policy is to find a balance between exploration and exploitation. Exploration is choosing those actions that have not been sampled much so far. Exploitation is about more extensively searching in the direction of actions you already have high expectations from. 