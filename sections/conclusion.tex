\section{conclusion}
In this paper we have evaluated a number of Tree Policies that are being used by MCTS in order to solve intractable problems. This evaluation took place in the domains of \rock and \poc: two POMCP problems that are both static and dynamic and have a large amount of states. Most notifiable is that performance is improved when there is a transition between exploration and exploitation during simulations. 

Using this result we have constructed \rsoft: a more domain independent version of \soft. At the minor cost of a slight drop in performance, \rsoft avoids the quirks of parameter tuning, that comes with the usage of \soft. 

As of such we get one step closer towards obtaining a golden Tree Policy that can be used without a lot of knowledge about the domain. Whether this actually holds, can be investigated by looking at more, different domains. Obtaining better performance might be feasible if we look at the ideas that other Tree Policies bring. Taking the amount of times an action has already been visited into account, like UCB1 does, might improve the obtained results. Another option would be to investigate whether one should behave differently depending on how deep you are in the tree, but this is left for future work.