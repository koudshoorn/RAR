\begin{abstract}
Many intractable problems, like the Travelling Salesman Problem and scheduling problems can in general be efficiently solved through sampling. Monte Carlo Tree Search is a sampling method that applies the intuition of Monte Carlo simulations, using repeated random samplings to search trees. Being the first to ever beat a professional Go player, MCTS is surely a promising research area. In recent years, MCTS has been extended to a variety of fields and domains by using so called Tree Policies rather than random sampling. These Tree Policies balance exploration and exploitation during the search process in order to determine which action to sample within the given timespan. We evaluated the advantages and disadvantages of two general search heuristics (\egreedy, \soft) in comparison to the `default' tree policy (UCB1) on several POMDP instances. We use the results to derive factors that influence search heuristic performance as well as suggest a variation on the traditional \soft algorithm that performs comparably but removes the necessity for hand-tuning parameters.
\end{abstract}