\begin{abstract}
Many intractable problems, like the Travelling Salesman Problem and scheduling problems can be sampled in polynomial time. MCTS uses this fact and applies the intuition of Monte Carlo simulations, by using repeated random samplings. Being the first to ever beat a professional Go player, MCTS is surely a promising research area. Over the years MCTS has improved even further by using so called Tree Policies instead of random sampling. These Tree Policies use a trade-off between exploration and exploitation to determine what to sample during the given timespan. We have evaluated the advantages and disadvantages of a few of these policies (UCB1, \egreedy and \soft) and have used them as building blocks for two novel Tree Policies. 
\end{abstract}